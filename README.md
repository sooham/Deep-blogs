# dl-study
Self taught materials of deep learning. Moreover, checking the latest Github repositories and GitXiv projects are necessary.

## Online courses
* [Graduate Summer School: Deep Learning, Feature Learning]
(http://www.ipam.ucla.edu/programs/summer-schools/graduate-summer-school-deep-learning-feature-learning/?tab=schedule)
<br>Popular researchers and professors in deep learning field teaches as a summer school. Although the materials are not the latest, tutorial contents are very beneficial.
* [IPAM Tutorials on Theano/Torch]
(https://github.com/clementfarabet/ipam-tutorials)
<br>Opensource of deep learning frameworks are introduced. They are introduced at one of the programs in above summer school.
* [Deep Learning - Informatics and Computational Sciences (2015-2016) - Yann LeCun - Collège de France]
(https://www.college-de-france.fr/site/en-yann-lecun/course-2015-2016.htm)
<br>Deep learning courses taught by Yann LeCun. English and French are provided. Lectures cover MLP, CNN, NLP, and unsupervised learning.
* [CSC2541 - Differential Inference and Generative Models]
(http://www.cs.toronto.edu/~duvenaud/courses/csc2541/index.html)
<br>The latest course related to generative models is introduced. Unfortunately, lecture video is not provided. However, its selected papers and several lecture notes are very beneficial. I think trying to read papers shown this material is good start point to study generative models.

## Blogs
* [Hacker's guide to Neural Networks]
(http://karpathy.github.io/neuralnets/)
<br>This is one of the posts of Andrej Karpathy's. I think this should be in must-read list.
* [Brandon Amos: Ph.D students in CMU]
(http://bamos.github.io/)
<br>Blog post: \<Image Completion with Deep Learning in TensorFlow\> was very beneficial.
* [What does the gradient flowing through batch normalization looks like ? – Clément thorey]
(http://cthorey.github.io/backpropagation/)
<br>Review and explanation of batch normalization
* [A Survey of Selected Papers on Deep Learning at ICML 2016]
(https://www.twosigma.com/insights/a-survey-of-selected-papers-on-deep-learning-at-icml-2016)
<br>To grasp latest research on deep learning, recent papers are needed to be read. To save time, these kinds of paper survey can be a reference.
* [Introduction to Deep Learning in Medicine and Biology]
(http://a12d.com/deep-learning-biomedicine)
<br>Interesting post of using deep learning in medicine and biology fields.

### Computer Vision
* [Adit Deshpande – CS Undergrad at UCLA ('19)]
(https://adeshpande3.github.io/adeshpande3.github.io/)
<br>Introduction of the state-of-the-art ConvNets, GANS, and Reinforcement learnings are posted.
* [One by One [ 1 x 1 ] Convolution - counter-intuitively useful – Aaditya Prakash (Adi)]
(http://iamaaditya.github.io/2016/03/one-by-one-convolution/)
<br>Why use 1x1 convolution in deep learning architecture is explained.
* [ResNets, HighwayNets, and DenseNets, Oh My!]
(https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32#.n12cjesup)
<br>State-of-the-art deep learning networks including ResNet and HighwayNets are posted with detailed explanation and implementation using TensorFlow. Other posts of this blog are also very beneficial.
* [Deconvolution and Checkerboard Artifacts]
(http://distill.pub/2016/deconv-checkerboard/)
<br>Great post of deconvolution comparison. The post is written by Google Brain researcher. I think this post is in must-read list.
* [Image Kernels explained visually]
(http://setosa.io/ev/image-kernels/)
<br>Although deep learning is not explained in this post, included content of image kernels is beneficial.

### Unsupervised Learning
* [Generating Faces with Deconvolution Networks]
(https://zo7.github.io/blog/2016/09/25/generating-faces.html)
<br>Generating faces is one of the applications of generative models. Its explanation is provided.
* [Generative adversarial autoencoders in Theano]
(https://swarbrickjones.wordpress.com/2016/01/24/generative-adversarial-autoencoders-in-theano/)
<br>Brief information of generative adversarial autoencoders
* [Variational Autoencoder in TensorFlow]
(https://jmetzen.github.io/2015-11-27/vae.html)
<br>Implementation of VAE using TensorFlow is explained step by step.
* [Fast Forward Labs: Under the Hood of the Variational Autoencoder (in Prose and Code)]
(http://blog.fastforwardlabs.com/post/149329060653/under-the-hood-of-the-variational-autoencoder-in)
<br>Explanation and implementation of VAE using TensorFlow are posted by machine intelligence research company called Fast Forward Labs.

### Natural Language Processing
* [Probably Approximately a Scientific Blog]
(http://veredshwartz.blogspot.kr/2016/01/representing-words.html)
<br>This post explains methods of representing words which is mostly used in natural language processing.

### Reinforcement Learning
* [Reinforcement Learning and DQN, learning to play from pixels]
(https://rubenfiszel.github.io/posts/rl4j/2016-08-24-Reinforcement-Learning-and-DQN.html)
<br>Post of reinforcement learning and DQN with detailed explanation and implementation.



### Papers
* [Paper Summaries]
(http://pemami4911.github.io/)
<br>Summaries of papers related to machine learning and various topics concerning artificial intelligence are posted.


### Frameworks
* [Beginner Tutorial: Neural Nets in Theano]
(http://outlace.com/Beginner-Tutorial-Theano/)
<br>Theano tutorial of neural nets
* [Understanding Natural Language with Deep Neural Networks Using Torch]
(https://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/)
<br>Explanation and implementation of natural language processing worked by NVDIA are posted. Torch is used.


## Others
* [Deep Learning | Jeremy D. Jackson, PhD]
(http://www.jeremydjacksonphd.com/category/deep-learning/)
<br>Curated list of deep learning resources.
* [Image Generation - handong1587]
(https://handong1587.github.io/deep_learning/2015/10/09/image-generation.html)
<br>Curated list of image generation by Handong University.

* [Classification datasets results]
(http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html)
<br>Current state of the art in object classification is collected. Well-known datasets: MNIST, CIFAR-10, CIFAR-100, STL-10, SVHN, ILSVRC2012 task 1 are shown.
* [Computer Vision and Pattern Recognition (cs.CV)]
(https://scirate.com/arxiv/cs.CV)
<br>Lists of CVPR papers with abstracts.
* [2D Visualization of a Convolutional Neural Network]
(http://scs.ryerson.ca/~aharley/vis/conv/flat.html)
<br>Visual intuition of convolutional neural network
* [Machine Learning - Reddit]
(https://www.reddit.com/r/MachineLearning/)
<br>Machine learning channel in Reddit.
